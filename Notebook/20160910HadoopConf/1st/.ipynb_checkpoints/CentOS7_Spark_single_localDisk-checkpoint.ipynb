{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Setting up Spark single node with local disk\n",
    "\n",
    "## OS: CentOS 7\n",
    "\n",
    "## Prerequisites\n",
    " * Your SSH Key to remote host.\n",
    " * Remote IP address or FQDN.\n",
    " * username in remote host.\n",
    "\n",
    "### Check SSH Key working directory\n",
    "\n",
    "### You could use shift + Enter to run the cell block\n",
    "### If In [ ] display [ * ], that mean it's working now, please wait a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('working direory is:') \n",
    "!pwd\n",
    "print()\n",
    "print('Try to create ./sshkey directory if we do not have one')\n",
    "![ -d ./sshkey ] || mkdir ./sshkey\n",
    "print()\n",
    "print('Check current directory')\n",
    "!ls -F ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please upload your SSH key to current ./sshkey in the jupyter homepage\n",
    " * like *.pem or *.rsa\n",
    "\n",
    "## The SSH Key could be delete in last block.\n",
    "\n",
    "### After you upload the SSH Key, we will change file permission to SSH Keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod 600 ./sshkey/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Please add your remote ip or FQDN to REMOTEHOST, \n",
    "### for example REMOTEHOST = '192.168.1.250' or REMOTEHOST = 'xxx.xxxx.xxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "REMOTEHOST = '192.168.1.250'\n",
    "print('REMOTEHOST is: ' + REMOTEHOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Please add your username to USERNAME\n",
    "### for example USERNAME = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USERNAME = 'cc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## please input your .pem file path\n",
    "### for example:  ./sshkey/YOURKEY.pem  or ./sshkey/id_ssh_rsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEYPATH = './sshkey/YOURKEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up SSH connection to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paramiko\n",
    "ssh = paramiko.SSHClient()\n",
    "\n",
    "ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "\n",
    "# define where is the SSH DSA key, use SSH key to connect remote host\n",
    "# key = paramiko.DSSKey.from_private_key_file('./sshkey/id_dsa')\n",
    "# if your use .pem key, please comment above line and use below\n",
    "key = paramiko.RSAKey.from_private_key_file(KEYPATH)\n",
    "\n",
    "\n",
    "ssh.connect(hostname=REMOTEHOST, username=USERNAME, pkey=key)\n",
    "\n",
    "# If you want to \n",
    "# ssh.connect(hostname=\"127.0.0.1\", username=\"openSUSE\", password=\"Password_there\")\n",
    "\n",
    "\n",
    "# Test uptime command with remote host\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('uptime')\n",
    "\n",
    "print(ssh_stdout.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sbt package in remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('curl   https://bintray.com/sbt/rpm/rpm  >   bintray-sbt-rpm.repo')\n",
    "print()\n",
    "print('\\n'.join(ssh_stderr.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('sudo mv  bintray-sbt-rpm.repo   /etc/yum.repos.d/')\n",
    "print()\n",
    "print('\\n'.join(ssh_stderr.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('sudo  yum  install epel-release  sbt   -y')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install java with open jdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('sudo yum install -y java-1.7.0-openjdk-devel')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('sudo yum install wget -y')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('wget http://www.scala-lang.org/files/archive/scala-2.10.1.tgz')\n",
    "print()\n",
    "print('\\n'.join(ssh_stderr.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('tar xvf scala-2.10.1.tgz')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('sudo mv scala-2.10.1 /usr/lib')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('sudo ln -s /usr/lib/scala-2.10.1/  /usr/lib/scala')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('echo \\'export PATH=$PATH:/usr/lib/scala/bin\\' >>  ~/.bashrc')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download spark with pre-build hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('wget    http://archive.apache.org/dist/spark/spark-1.4.0/spark-1.4.0-bin-hadoop2.6.tgz')\n",
    "print()\n",
    "print('\\n'.join(ssh_stderr.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('tar   zxvf   spark-*.tgz')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()\n",
    "\n",
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('mv  ~/spark*/  ~/spark')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show scala package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('/usr/lib/scala-2.10.1/bin/scala -version')\n",
    "print()\n",
    "print('\\n'.join(ssh_stderr.readlines()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command('jps')\n",
    "print()\n",
    "print('\\n'.join(ssh_stdout.readlines()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==== You can use ssh to login remote server and change your directory to spark folder and run spark-shell now ====\n",
    "\n",
    "In the remote server\n",
    "\n",
    "\\$ cd spark*\n",
    "\n",
    "\\$ bin/spark-shell\n",
    "\n",
    "==== Your SparkUI will be port :4040, just open your browser, test localhost:4040 in URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## For secuirty reason, you could use below block to delete your ssh Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm ./sshkey/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
